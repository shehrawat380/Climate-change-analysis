{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4c4416",
   "metadata": {},
   "source": [
    "# Climate Change Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88218a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02 â€” Modeling\n",
    "\n",
    "# --- Hybrid dataset loader ---\n",
    "import os, io\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"../data/clean_climate.csv\"\n",
    "\n",
    "if os.path.exists(DATA_PATH):\n",
    "    print(f\"Loading dataset from {DATA_PATH}\")\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "else:\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload()\n",
    "        file_name = list(uploaded.keys())[0]\n",
    "        df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
    "        print(f\"Loaded uploaded file: {file_name}\")\n",
    "    except Exception as e:\n",
    "        from tkinter import Tk, filedialog\n",
    "        Tk().withdraw()\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"CSV files\",\"*.csv\")])\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Loaded local file: {file_path}\")\n",
    "\n",
    "# --- Modeling pipeline ---\n",
    "import numpy as np\n",
    "from src.data_preprocessing import basic_cleaning, train_val_test_split, scale_numeric\n",
    "from src.modeling import train_random_forest, evaluate, save_artifacts\n",
    "from src.feature_engineering import add_time_lags, add_rolling_features\n",
    "\n",
    "df = basic_cleaning(df)\n",
    "\n",
    "# Choose target\n",
    "target = next((c for c in df.columns if 'anomaly' in c.lower() or 'target' in c.lower()),\n",
    "              df.select_dtypes('number').columns.tolist()[0])\n",
    "print('Target:', target)\n",
    "\n",
    "# Optional time features\n",
    "df = add_time_lags(df, target)\n",
    "df = add_rolling_features(df, target)\n",
    "\n",
    "# Keep numeric only and drop NAs for baseline\n",
    "df_num = df.select_dtypes(include=[np.number]).dropna()\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(df_num, target)\n",
    "Xtr, Xv, Xte, scaler = scale_numeric(X_train, X_val, X_test)\n",
    "\n",
    "# Train RF\n",
    "result = train_random_forest(Xtr, y_train, Xv, y_val)\n",
    "print(\"Validation metrics:\", result['val_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3486e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_metrics = evaluate(result['model'], Xte, y_test)\n",
    "print(\"Test metrics:\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12888573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts\n",
    "save_artifacts(result['model'], scaler, out_dir='../artifacts', prefix='rf')\n",
    "print('Artifacts saved: ../artifacts/rf_model.pkl, ../artifacts/rf_scaler.pkl')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
